# make_jlpt_audio.py
# -*- coding: utf-8 -*-
"""
JLPT ì¼ë³¸ì–´ ë‹¨ì–´ ì˜¤ë””ì˜¤ ìƒì„±ê¸°

ê¸°ëŠ¥:
- jlpt_n5_vocabs.jsonìœ¼ë¡œë¶€í„° ì¼ë³¸ì–´ ë‹¨ì–´ ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„±
- word.mp3: ì¼ë³¸ì–´ ë‹¨ì–´(kana) ìŒì„± í•©ì„±
- gloss.mp3: ì¼ë³¸ì–´ ë‹¨ì–´ + ë¬´ìŒ + í•œêµ­ì–´ ëœ» í•©ì„±
- example.mp3: ì¼ë³¸ì–´ ì˜ˆë¬¸ ìŒì„± í•©ì„±

ì¶œë ¥ êµ¬ì¡°:
jlpt/n5/{romaji}/
â”œâ”€â”€ word.mp3     (kana ì½ê¸°)
â”œâ”€â”€ gloss.mp3    (kana + í•œêµ­ì–´ ëœ»)
â””â”€â”€ example.mp3  (ì˜ˆë¬¸)

ë³´ì´ìŠ¤:
- ì¼ë³¸ì–´: ja-JP-Chirp3-HD-Orus (ë‚¨ì„±), ja-JP-Chirp3-HD-Achernar (ì—¬ì„±) ìˆœí™˜
- í•œêµ­ì–´ (gloss): ko-KR-Neural2-C (ë‚¨ì„±), ko-KR-Neural2-B (ì—¬ì„±) ìˆœí™˜
- í•œêµ­ì–´ (example): ko-KR-Chirp3-HD-Orus (ë‚¨ì„±), ko-KR-Chirp3-HD-Achernar (ì—¬ì„±) ìˆœí™˜

í•„ìˆ˜: pip install google-cloud-texttospeech pydub, FFmpeg, GCP ADC ì„¤ì •
"""

import os

os.environ["GRPC_DNS_RESOLVER"] = "native"

import sys, re, json, time
from io import BytesIO
from typing import Any, Dict, List, Optional

from google.cloud import texttospeech
from pydub import AudioSegment

# ===== íŒŒë¼ë¯¸í„° =====
TARGET_DBFS = float(os.getenv("TARGET_DBFS", "-16.0"))
GLOSS_GAP_MS = int(os.getenv("GLOSS_GAP_MS", "1000"))  # wordâ†’koGloss ê°„ê²©(ê¸°ë³¸ 1.0ì´ˆ)
COMMA_GAP_MS = int(os.getenv("COMMA_GAP_MS", "500"))  # koGloss ë‚´ ì½¤ë§ˆ ê°„ê²©(ê¸°ë³¸ 0.5ì´ˆ)
MAX_RETRY = int(os.getenv("MAX_RETRY", "2"))
RETRY_BACKOFF_SEC = float(os.getenv("RETRY_BACKOFF_SEC", "0.8"))

# ì¼ë³¸ì–´ ë³´ì´ìŠ¤ (Chirp3 HD) - Orus/Achernar ìˆœí™˜
JA_MALE = os.getenv("JA_MALE", "ja-JP-Chirp3-HD-Orus")  # ì¼ë³¸ì–´ ë‚¨ì„± ë³´ì´ìŠ¤
JA_FEMALE = os.getenv("JA_FEMALE", "ja-JP-Chirp3-HD-Achernar")  # ì¼ë³¸ì–´ ì—¬ì„± ë³´ì´ìŠ¤

# í•œêµ­ì–´ ë³´ì´ìŠ¤ (glossìš© Neural2)
KO_NEURAL_MALE = os.getenv("KO_NEURAL_MALE", "ko-KR-Neural2-C")  # í•œêµ­ì–´ Neural2 ë‚¨ì„±
KO_NEURAL_FEMALE = os.getenv("KO_NEURAL_FEMALE", "ko-KR-Neural2-B")  # í•œêµ­ì–´ Neural2 ì—¬ì„±

# í•œêµ­ì–´ ë³´ì´ìŠ¤ (exampleìš© Chirp3)
KO_CHIRP_MALE = os.getenv("KO_CHIRP_MALE", "ko-KR-Chirp3-HD-Orus")  # í•œêµ­ì–´ Chirp3 ë‚¨ì„±
KO_CHIRP_FEMALE = os.getenv("KO_CHIRP_FEMALE", "ko-KR-Chirp3-HD-Achernar")  # í•œêµ­ì–´ Chirp3 ì—¬ì„±


# í´ë°± í›„ë³´
def _parse_list(s: str) -> List[str]:
    return [x.strip() for x in s.split(",") if x.strip()]


JA_MALE_FALLBACKS = _parse_list(
    os.getenv(
        "JA_MALE_FALLBACKS",
        "ja-JP-Chirp3-HD-Orus,ja-JP-Neural2-C,ja-JP-Neural2-D,ja-JP-Standard-C,ja-JP-Standard-D",
    )
)
JA_FEMALE_FALLBACKS = _parse_list(
    os.getenv(
        "JA_FEMALE_FALLBACKS",
        "ja-JP-Chirp3-HD-Achernar,ja-JP-Neural2-B,ja-JP-Standard-B,ja-JP-Standard-A",
    )
)

# glossìš© í•œêµ­ì–´ Neural2 í´ë°±
KO_NEURAL_MALE_FALLBACKS = _parse_list(
    os.getenv(
        "KO_NEURAL_MALE_FALLBACKS",
        "ko-KR-Neural2-C,ko-KR-Standard-C,ko-KR-Standard-D",
    )
)
KO_NEURAL_FEMALE_FALLBACKS = _parse_list(
    os.getenv(
        "KO_NEURAL_FEMALE_FALLBACKS",
        "ko-KR-Neural2-B,ko-KR-Standard-A,ko-KR-Standard-B",
    )
)

# exampleìš© í•œêµ­ì–´ Chirp3 í´ë°±
KO_CHIRP_MALE_FALLBACKS = _parse_list(
    os.getenv(
        "KO_CHIRP_MALE_FALLBACKS",
        "ko-KR-Chirp3-HD-Orus,ko-KR-Neural2-C,ko-KR-Standard-C",
    )
)
KO_CHIRP_FEMALE_FALLBACKS = _parse_list(
    os.getenv(
        "KO_CHIRP_FEMALE_FALLBACKS",
        "ko-KR-Chirp3-HD-Achernar,ko-KR-Neural2-B,ko-KR-Standard-A",
    )
)


# ===== ìœ í‹¸ =====
def normalize_spaces(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").strip())


def sanitize_filename(name: str) -> str:
    name = re.sub(r'[\\/*?:"<>|]', "", str(name or ""))
    return name.strip().lower() or "unnamed"


def loudness_normalize(seg: AudioSegment, target_dbfs: float) -> AudioSegment:
    if seg.duration_seconds <= 0 or seg.dBFS == float("-inf"):
        return seg
    return seg.apply_gain(target_dbfs - seg.dBFS)


def build_output_paths(romaji: str, level: str = "n5") -> Dict[str, str]:
    """JLPT ì¶œë ¥ ê²½ë¡œ ìƒì„±"""
    word_folder = sanitize_filename(romaji)
    out_dir = os.path.normpath(os.path.join("jlpt", level, word_folder))
    os.makedirs(out_dir, exist_ok=True)
    return {
        "dir": out_dir,
        "word": os.path.join(out_dir, "word.mp3"),
        "gloss": os.path.join(out_dir, "gloss.mp3"),
        "example": os.path.join(out_dir, "example.mp3"),
    }


def clean_ko_gloss(text: str) -> str:
    """í•œêµ­ì–´ ëœ» ì „ì²˜ë¦¬ - ê´„í˜¸ ë° ê´„í˜¸ ë‚´ìš© ì™„ì „ ì œê±°"""
    if not text:
        return ""
    s = normalize_spaces(text)

    # ë¬¼ê²° í‘œì‹œ(~)ë¥¼ 'ë¬´ì—‡ë¬´ì—‡'ìœ¼ë¡œ ì¹˜í™˜
    s = s.replace("~", "ë¬´ì—‡ë¬´ì—‡")

    # ê´„í˜¸ ë° ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì™„ì „íˆ ì œê±°
    s = re.sub(r"[ï¼ˆ(][^ï¼‰)]*[ï¼‰)]", "", s)

    # í’ˆì‚¬ ì•½ì–´ ì œê±° (ì˜ì–´, í•œêµ­ì–´ í’ˆì‚¬ í‘œì‹œ ëª¨ë‘)
    s = re.sub(
        r"\b(?:pron|n|v|adj|adv|prep|conj|int|interj|aux|det|num)\.\s*",
        "",
        s,
        flags=re.I,
    )
    # í•œêµ­ì–´ í’ˆì‚¬ í‘œì‹œ ì œê±° (ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬, ë¶€ì‚¬, ê°íƒ„ì‚¬ ë“±)
    s = re.sub(
        r"\b(?:ëª…ì‚¬|ë™ì‚¬|í˜•ìš©ì‚¬|ë¶€ì‚¬|ê°íƒ„ì‚¬|ëŒ€ëª…ì‚¬|ì „ì¹˜ì‚¬|ì ‘ì†ì‚¬|ì¡°ë™ì‚¬|ê´€ì‚¬|ìˆ˜ì‚¬)\.\s*",
        "",
        s,
    )

    # íŠ¹ìˆ˜ë¬¸ì ì œê±° (ìŠ¬ë˜ì‹œ ë“±)
    s = re.sub(r"[/\\|<>\"']", " ", s)

    s = normalize_spaces(s).strip(" ;,Â·")
    return s


def clean_japanese_text(text: str) -> str:
    """ì¼ë³¸ì–´ í…ìŠ¤íŠ¸ ì •ë¦¬ - íŠ¹ìˆ˜ë¬¸ì ë° ê´„í˜¸ ì²˜ë¦¬"""
    if not text:
        return ""
    s = normalize_spaces(text)

    # ê´„í˜¸ì™€ ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì œê±° (ì¼ë³¸ì–´ í¬í•¨)
    s = re.sub(r"[ï¼ˆ(][^ï¼‰)]*[ï¼‰)]", "", s)

    # íŠ¹ìˆ˜ë¬¸ì ì œê±° (ìŠ¬ë˜ì‹œ ë“±)
    s = re.sub(r"[/\\|<>\"']", " ", s)

    return normalize_spaces(s)


# ===== ì„±ë³„ ìˆœí™˜ =====
def is_male(index_zero_based: int) -> bool:
    return index_zero_based % 2 == 0  # 0,2,4,... ë‚¨ì„± / 1,3,5,... ì—¬ì„±


def voices_for_index(idx0: int) -> Dict[str, str]:
    """ì¸ë±ìŠ¤ë³„ ë³´ì´ìŠ¤ ì„ íƒ"""
    if is_male(idx0):
        return {
            "ja": JA_MALE,
            "ko_neural": KO_NEURAL_MALE,  # glossìš©
            "ko_chirp": KO_CHIRP_MALE,    # exampleìš©
            "gender": "male"
        }
    else:
        return {
            "ja": JA_FEMALE,
            "ko_neural": KO_NEURAL_FEMALE,  # glossìš©
            "ko_chirp": KO_CHIRP_FEMALE,    # exampleìš©
            "gender": "female"
        }


# ===== TTS =====
def tts_client() -> texttospeech.TextToSpeechClient:
    return texttospeech.TextToSpeechClient()


def synthesize_lang(
    tts: texttospeech.TextToSpeechClient, text: str, voice_name: str, language_code: str
) -> Optional[AudioSegment]:
    """ë‹¨ì¼ ì–¸ì–´ TTS í•©ì„±"""
    text = normalize_spaces(text)
    if not text:
        return AudioSegment.silent(duration=0)

    voice = texttospeech.VoiceSelectionParams(
        language_code=language_code, name=voice_name
    )
    cfg = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)
    inp = texttospeech.SynthesisInput(text=text)

    for attempt in range(1, MAX_RETRY + 2):
        try:
            resp = tts.synthesize_speech(input=inp, voice=voice, audio_config=cfg)
            seg = AudioSegment.from_file(BytesIO(resp.audio_content), format="mp3")
            return loudness_normalize(seg, TARGET_DBFS)
        except Exception as e:
            if attempt <= MAX_RETRY:
                time.sleep(RETRY_BACKOFF_SEC * attempt)
            else:
                print(f"  âŒ TTS ì‹¤íŒ¨(name={voice_name}, lang={language_code}): {e}")
                return None
    return None


def synthesize_lang_try_voices(
    tts: texttospeech.TextToSpeechClient,
    text: str,
    language_code: str,
    voices: List[str],
) -> Optional[AudioSegment]:
    """ë³´ì´ìŠ¤ í›„ë³´ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœì°¨ ì‹œë„"""
    for idx, vname in enumerate([v for v in voices if v]):
        seg = synthesize_lang(tts, text, vname, language_code)
        if seg is not None and len(seg) > 0:
            if idx > 0:
                print(f"  â†ªï¸ ëŒ€ì²´ ë³´ì´ìŠ¤ ì‚¬ìš©: {vname}")
            return seg
    print(f"  âŒ ëª¨ë“  ë³´ì´ìŠ¤ ì‹¤íŒ¨: {', '.join(voices)}")
    return None


def synthesize_with_commas_try_voices(
    tts: texttospeech.TextToSpeechClient,
    text: str,
    language_code: str,
    comma_gap_ms: int,
    voices: List[str],
) -> Optional[AudioSegment]:
    """ì‰¼í‘œ ë¶„í•  í•©ì„±"""
    text = normalize_spaces(text)
    if not text:
        return AudioSegment.silent(duration=0)

    parts = [p.strip() for p in re.split(r"[,\uFF0C]", text) if p.strip()]

    for idx_voice, vname in enumerate([v for v in voices if v]):
        silence = AudioSegment.silent(duration=comma_gap_ms)
        merged = AudioSegment.empty()
        ok = True

        for idx, part in enumerate(parts):
            seg = synthesize_lang(tts, part, vname, language_code)
            if seg is None or len(seg) == 0:
                ok = False
                break
            merged += seg
            if idx != len(parts) - 1:
                merged += silence

        if ok:
            if idx_voice > 0:
                print(f"  â†ªï¸ ëŒ€ì²´ ë³´ì´ìŠ¤ ì‚¬ìš©: {vname}")
            return loudness_normalize(merged, TARGET_DBFS)

    print(f"  âŒ ì‰¼í‘œ ë¶„í•  í•©ì„± ì‹¤íŒ¨: {', '.join(voices)}")
    return None


# ===== IO =====
def load_items(json_path: str) -> List[Dict[str, Any]]:
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    return data if isinstance(data, list) else [data]


def ensure_parent_dir(path: str) -> None:
    d = os.path.dirname(os.path.normpath(path))
    if d and not os.path.exists(d):
        os.makedirs(d, exist_ok=True)


def is_japanese_char(char: str) -> bool:
    """ì¼ë³¸ì–´ ë¬¸ìì¸ì§€ íŒë³„ (íˆë¼ê°€ë‚˜, ê°€íƒ€ì¹´ë‚˜, í•œì)"""
    code = ord(char)
    return (
        0x3040 <= code <= 0x309F  # íˆë¼ê°€ë‚˜
        or 0x30A0 <= code <= 0x30FF  # ê°€íƒ€ì¹´ë‚˜
        or 0x4E00 <= code <= 0x9FAF  # CJK í•œì
        or 0x3400 <= code <= 0x4DBF
    )  # CJK í™•ì¥ A


def split_mixed_text(text: str) -> List[tuple]:
    """ì¼ë³¸ì–´/í•œêµ­ì–´ í˜¼í•© í…ìŠ¤íŠ¸ë¥¼ ë¶„ë¦¬í•˜ì—¬ (ì–¸ì–´, í…ìŠ¤íŠ¸) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    if not text:
        return []

    # ëª¨ë“  ê´„í˜¸ì™€ ê´„í˜¸ ì•ˆì˜ ë‚´ìš©ì„ ì™„ì „íˆ ì œê±°
    processed_text = re.sub(r"[ï¼ˆ(][^ï¼‰)]*[ï¼‰)]", "", text)

    segments = []
    current_text = ""
    current_lang = None

    for char in processed_text:
        if char.strip():  # ê³µë°±ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
            is_ja = is_japanese_char(char)
            lang = "ja" if is_ja else "ko"

            if current_lang is None:
                current_lang = lang
                current_text = char
            elif current_lang == lang:
                current_text += char
            else:
                # ì–¸ì–´ê°€ ë°”ë€œ - ì´ì „ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥
                if current_text.strip():
                    segments.append((current_lang, current_text.strip()))
                current_lang = lang
                current_text = char
        else:
            current_text += char  # ê³µë°±ì€ ê·¸ëŒ€ë¡œ ì¶”ê°€

    # ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥
    if current_text.strip():
        segments.append((current_lang, current_text.strip()))

    return segments


def synthesize_mixed_script(
    tts: texttospeech.TextToSpeechClient,
    mixed_text: str,
    voices: Dict[str, str],
    ja_candidates: List[str],
    ko_chirp_candidates: List[str],  # exampleìš© Chirp3 ë³´ì´ìŠ¤
) -> Optional[AudioSegment]:
    """ì¼ë³¸ì–´/í•œêµ­ì–´ í˜¼í•© í…ìŠ¤íŠ¸ë¥¼ ê°ê° í•´ë‹¹ ì–¸ì–´ ë³´ì´ìŠ¤ë¡œ í•©ì„± (exampleìš©)"""
    segments = split_mixed_text(mixed_text)
    if not segments:
        return None

    merged = AudioSegment.empty()

    for lang, text in segments:
        if lang == "ja":
            # ì¼ë³¸ì–´ ë¶€ë¶„ - íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬ í›„ ì¼ë³¸ì–´ Chirp3 ë³´ì´ìŠ¤ ì‚¬ìš©
            cleaned_text = clean_japanese_text(text)
            seg = synthesize_lang_try_voices(tts, cleaned_text, "ja-JP", ja_candidates)
        else:
            # í•œêµ­ì–´ ë¶€ë¶„ - exampleìš©ì´ë¯€ë¡œ Chirp3 ë³´ì´ìŠ¤ ì‚¬ìš©, ì‰¼í‘œ ë¶„í•  ì ìš©
            cleaned_text = clean_ko_gloss(text)
            seg = synthesize_with_commas_try_voices(
                tts, cleaned_text, "ko-KR", COMMA_GAP_MS, ko_chirp_candidates
            )

        if seg is None or len(seg) == 0:
            print(
                f"    âš ï¸ {lang} ë¶€ë¶„ í•©ì„± ì‹¤íŒ¨: '{text[:50]}{'...' if len(text) > 50 else ''}'"
            )
            return None

        merged += seg
        # ì„¸ê·¸ë¨¼íŠ¸ ê°„ ì§§ì€ ë¬´ìŒ ì¶”ê°€ (200ms)
        merged += AudioSegment.silent(duration=200)

    return loudness_normalize(merged, TARGET_DBFS)


# ===== ë©”ì¸ íŒŒì´í”„ë¼ì¸ =====
def extract_level_from_filename(json_path: str) -> str:
    """JSON íŒŒì¼ëª…ì—ì„œ JLPT ë ˆë²¨ ì¶”ì¶œ (ì˜ˆ: jlpt_n4_vocabs.json -> n4)"""
    import re
    filename = os.path.basename(json_path)
    match = re.search(r'jlpt_?(n[1-5])', filename, re.IGNORECASE)
    return match.group(1).lower() if match else "n5"

def process(json_path: str) -> None:
    try:
        items = load_items(json_path)
    except Exception as e:
        print(f"JSON ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    try:
        tts = tts_client()
    except Exception as e:
        print("Google Cloud ì¸ì¦ ì‹¤íŒ¨ ë˜ëŠ” í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨:", e)
        return

    level = extract_level_from_filename(json_path)
    total = len(items)
    print(f"ğŸ§ JLPT ì˜¤ë””ì˜¤ ìƒì„± ì‹œì‘ (items={total}, level={level})")
    print(f"    JA: male={JA_MALE}, female={JA_FEMALE}")
    print(f"    KO(gloss): male={KO_NEURAL_MALE}, female={KO_NEURAL_FEMALE}")
    print(f"    KO(example): male={KO_CHIRP_MALE}, female={KO_CHIRP_FEMALE}")
    print(f"    gaps: gloss={GLOSS_GAP_MS}ms, comma={COMMA_GAP_MS}ms")
    print(
        "ğŸ“ ëª¨ë“œ: word=ja-JP(Chirp3 HD), gloss=ja-JP(Chirp3)+ko-KR(Neural2), example=ja-JP(Chirp3)+ko-KR(Chirp3), ì„±ë³„ ìˆœí™˜(ë‚¨â†’ì—¬â†’ë‚¨â€¦)\n"
    )

    last_saved: Optional[str] = None
    fails: List[str] = []

    for i, item in enumerate(items):
        lemma = item.get("lemma", "")
        kana = item.get("kana", "")
        romaji = item.get("romaji", "")
        ko_gloss_raw = item.get("koGloss", "") or item.get("koChirpScript", "")
        example = item.get("example", "")
        audio_paths = item.get("audio", {})

        if not lemma or not kana or not romaji:
            print(
                f"[{i+1}/{total}] ê±´ë„ˆëœ€: í•„ìˆ˜ í•„ë“œ ëˆ„ë½ â†’ lemma={lemma}, kana={kana}, romaji={romaji}"
            )
            continue

        # ì¶œë ¥ ê²½ë¡œ ìƒì„±
        try:
            paths = build_output_paths(romaji, level)
        except Exception as e:
            print(f"[{i+1}/{total}] '{romaji}' ê²½ë¡œ ì˜¤ë¥˜: {e}")
            fails.append(f"{romaji}\tPATH_ERROR:{e}")
            continue

        # í´ë”ê°€ ì´ë¯¸ ì¡´ì¬í•˜ê³  ëª¨ë“  íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        if os.path.exists(paths["dir"]):
            has_word = os.path.exists(paths["word"])
            has_gloss = os.path.exists(paths["gloss"]) if ko_gloss_raw else True
            has_example = os.path.exists(paths["example"]) if item.get("koChirpScript", "") else True

            if has_word and has_gloss and has_example:
                print(f"[{i+1}/{total}] '{lemma}({kana})' â†’ ì´ë¯¸ ì¡´ì¬, ê±´ë„ˆëœ€")
                continue

        v = voices_for_index(i)
        print(
            f"[{i+1}/{total}] '{lemma}({kana})' â†’ dir='{paths['dir']}', "
            f"ja={v['ja']}, ko_gloss={v['ko_neural']}, ko_example={v['ko_chirp']} (gender={v['gender']})"
        )

        # 1) word.mp3 (ì¼ë³¸ì–´ kana - Chirp3)
        ja_candidates = [v["ja"]] + (
            JA_MALE_FALLBACKS if v["gender"] == "male" else JA_FEMALE_FALLBACKS
        )
        word_seg = synthesize_lang_try_voices(tts, kana, "ja-JP", ja_candidates)

        if word_seg is None or len(word_seg) == 0:
            print("  âŒ word í•©ì„± ì‹¤íŒ¨")
            fails.append(f"{romaji}\tWORD_SYNTH_FAIL:{v['ja']}")
            continue

        try:
            word_seg.export(paths["word"], format="mp3")
            print("  âœ… word.mp3 ì €ì¥")

            # ì¶”ê°€ ì €ì¥: audio.word (ì˜µì…˜)
            if audio_paths.get("word"):
                alt_path = os.path.normpath(audio_paths["word"])
                ensure_parent_dir(alt_path)
                word_seg.export(alt_path, format="mp3")
                print(f"    â†ªï¸ ì¶”ê°€ ì €ì¥: {alt_path}")
        except Exception as e:
            print(f"  âš ï¸ word ì €ì¥ ì‹¤íŒ¨: {e}")
            fails.append(f"{romaji}\tWORD_SAVE_FAIL:{e}")
            continue

        # 2) gloss.mp3 = kana(Chirp3) + ë¬´ìŒ + koGloss(Neural2)
        ko_gloss = clean_ko_gloss(ko_gloss_raw)
        if ko_gloss:
            # glossìš© Neural2 ë³´ì´ìŠ¤ ì‚¬ìš©
            ko_neural_candidates = [v["ko_neural"]] + (
                KO_NEURAL_MALE_FALLBACKS if v["gender"] == "male" else KO_NEURAL_FEMALE_FALLBACKS
            )
            ko_seg = synthesize_with_commas_try_voices(
                tts, ko_gloss, "ko-KR", COMMA_GAP_MS, ko_neural_candidates
            )

            if ko_seg is not None and len(ko_seg) > 0:
                gloss_seg = (
                    word_seg + AudioSegment.silent(duration=GLOSS_GAP_MS) + ko_seg
                )
                gloss_seg = loudness_normalize(gloss_seg, TARGET_DBFS)

                try:
                    gloss_seg.export(paths["gloss"], format="mp3")
                    print("  âœ… gloss.mp3 ì €ì¥ (Neural2)")

                    # ì¶”ê°€ ì €ì¥: audio.gloss (ì˜µì…˜)
                    if audio_paths.get("gloss"):
                        alt_path = os.path.normpath(audio_paths["gloss"])
                        ensure_parent_dir(alt_path)
                        gloss_seg.export(alt_path, format="mp3")
                        print(f"    â†ªï¸ ì¶”ê°€ ì €ì¥: {alt_path}")
                except Exception as e:
                    print(f"  âš ï¸ gloss ì €ì¥ ì‹¤íŒ¨: {e}")
                    fails.append(f"{romaji}\tGLOSS_SAVE_FAIL:{e}")
            else:
                print("  âš ï¸ koGloss í•©ì„± ì‹¤íŒ¨")
                fails.append(f"{romaji}\tKOGLOSS_SYNTH_FAIL")
        else:
            print("  âš ï¸ koGloss ë¹„ì–´ìˆìŒ â†’ gloss ìƒëµ")

        # 3) example.mp3 (koChirpScript - ì¼ë³¸ì–´ Chirp3 / í•œêµ­ì–´ Chirp3 ë¶„ë¦¬ í•©ì„±)
        ko_chirp_script = item.get("koChirpScript", "")
        if ko_chirp_script:
            # exampleìš© Chirp3 ë³´ì´ìŠ¤ ì‚¬ìš©
            ko_chirp_candidates = [v["ko_chirp"]] + (
                KO_CHIRP_MALE_FALLBACKS if v["gender"] == "male" else KO_CHIRP_FEMALE_FALLBACKS
            )
            example_seg = synthesize_mixed_script(
                tts, ko_chirp_script, v, ja_candidates, ko_chirp_candidates
            )

            if example_seg is not None and len(example_seg) > 0:
                try:
                    example_seg.export(paths["example"], format="mp3")
                    print("  âœ… example.mp3 ì €ì¥ (koChirpScript - Chirp3 í˜¼í•©)")

                    # ì¶”ê°€ ì €ì¥: audio.example (ì˜µì…˜)
                    if audio_paths.get("example"):
                        alt_path = os.path.normpath(audio_paths["example"])
                        ensure_parent_dir(alt_path)
                        example_seg.export(alt_path, format="mp3")
                        print(f"    â†ªï¸ ì¶”ê°€ ì €ì¥: {alt_path}")
                except Exception as e:
                    print(f"  âš ï¸ example ì €ì¥ ì‹¤íŒ¨: {e}")
                    fails.append(f"{romaji}\tEXAMPLE_SAVE_FAIL:{e}")
            else:
                print("  âš ï¸ koChirpScript í•©ì„± ì‹¤íŒ¨")
                fails.append(f"{romaji}\tKOCHIRPSCRIPT_SYNTH_FAIL")
        else:
            print("  âš ï¸ koChirpScript ë¹„ì–´ìˆìŒ â†’ example ìƒëµ")

        last_saved = romaji

    # ë§ˆë¬´ë¦¬
    try:
        with open("ë§ˆì§€ë§‰ ìƒì„± ë‹¨ì–´.txt", "w", encoding="utf-8") as f:
            f.write((last_saved or "").strip())
    except Exception:
        pass

    if fails:
        with open("ìƒì„± ì‹¤íŒ¨ ëª©ë¡.txt", "w", encoding="utf-8") as f:
            f.write("\n".join(fails) + "\n")
        print(f"\nâš ï¸ ì‹¤íŒ¨ {len(fails)}ê±´ â†’ 'ìƒì„± ì‹¤íŒ¨ ëª©ë¡.txt' ê¸°ë¡")
    else:
        print("\nâœ… ëª¨ë“  í•­ëª© ì²˜ë¦¬ ì™„ë£Œ(ì‹¤íŒ¨ ì—†ìŒ)")


if __name__ == "__main__":
    json_file = sys.argv[1] if len(sys.argv) > 1 else "jlpt_n4_vocabs.json"
    process(json_file)