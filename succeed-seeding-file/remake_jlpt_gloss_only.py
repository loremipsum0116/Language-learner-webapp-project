# remake_jlpt_gloss_only.py
# -*- coding: utf-8 -*-
"""
JLPT ì¼ë³¸ì–´ ë‹¨ì–´ gloss.mp3 íŒŒì¼ë§Œ ì¬ìƒì„±

ê¸°ëŠ¥:
- ê¸°ì¡´ jlpt í´ë” êµ¬ì¡°ì—ì„œ gloss.mp3 íŒŒì¼ë§Œ êµì²´
- ì¼ë³¸ì–´: ê¸°ì¡´ Chirp3 ëª¨ë¸ ìœ ì§€
- í•œêµ­ì–´: ko-KR-Neural12-C (ë‚¨ì„±), ko-KR-Neural12-B (ì—¬ì„±) ì‚¬ìš©
- íƒ€ì´ë°: ì¼ë³¸ì–´ â†’ 1ì´ˆ ëŒ€ê¸° â†’ í•œêµ­ì–´ (ì½¤ë§ˆì‹œ 0.5ì´ˆ ëŒ€ê¸°)
- ê´„í˜¸ ì²˜ë¦¬: í•œêµ­ì–´ì—ì„œ ê´„í˜¸ ë° ë‚´ìš© ì™„ì „ ì œê±°

ì¶œë ¥: ê¸°ì¡´ jlpt/n5/{romaji}/gloss.mp3 íŒŒì¼ë“¤ êµì²´

í•„ìˆ˜: pip install google-cloud-texttospeech pydub, FFmpeg, GCP ADC ì„¤ì •
"""

import os

os.environ["GRPC_DNS_RESOLVER"] = "native"

import sys, re, json, time, glob
from io import BytesIO
from typing import Any, Dict, List, Optional

from google.cloud import texttospeech
from pydub import AudioSegment

# ===== íŒŒë¼ë¯¸í„° =====
TARGET_DBFS = float(os.getenv("TARGET_DBFS", "-16.0"))
GLOSS_GAP_MS = int(os.getenv("GLOSS_GAP_MS", "1000"))  # wordâ†’koGloss ê°„ê²© (1ì´ˆ)
COMMA_GAP_MS = int(os.getenv("COMMA_GAP_MS", "500"))   # koGloss ë‚´ ì½¤ë§ˆ ê°„ê²© (0.5ì´ˆ)
MAX_RETRY = int(os.getenv("MAX_RETRY", "2"))
RETRY_BACKOFF_SEC = float(os.getenv("RETRY_BACKOFF_SEC", "0.8"))

# ì¼ë³¸ì–´ ë³´ì´ìŠ¤ (ê¸°ì¡´ Chirp3 HD ìœ ì§€)
JA_MALE = os.getenv("JA_MALE", "ja-JP-Chirp3-HD-Orus")
JA_FEMALE = os.getenv("JA_FEMALE", "ja-JP-Chirp3-HD-Achernar")

# í•œêµ­ì–´ ë³´ì´ìŠ¤ (Neural2ë¡œ ë³€ê²½)
KO_MALE = "ko-KR-Neural2-C"       # ë‚¨ì„± ë³´ì´ìŠ¤
KO_FEMALE = "ko-KR-Neural2-B"     # ì—¬ì„± ë³´ì´ìŠ¤

# í´ë°± í›„ë³´
def _parse_list(s: str) -> List[str]:
    return [x.strip() for x in s.split(",") if x.strip()]

JA_MALE_FALLBACKS = _parse_list("ja-JP-Chirp3-HD-Orus,ja-JP-Neural2-C,ja-JP-Neural2-D")
JA_FEMALE_FALLBACKS = _parse_list("ja-JP-Chirp3-HD-Achernar,ja-JP-Neural2-B,ja-JP-Standard-B")
KO_MALE_FALLBACKS = _parse_list("ko-KR-Neural12-C,ko-KR-Neural2-C,ko-KR-Standard-C")
KO_FEMALE_FALLBACKS = _parse_list("ko-KR-Neural12-B,ko-KR-Neural2-B,ko-KR-Standard-B")

# ===== ìœ í‹¸ =====
def normalize_spaces(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").strip())

def loudness_normalize(seg: AudioSegment, target_dbfs: float) -> AudioSegment:
    if seg.duration_seconds <= 0 or seg.dBFS == float("-inf"):
        return seg
    return seg.apply_gain(target_dbfs - seg.dBFS)

def clean_ko_gloss_strict(text: str) -> str:
    """í•œêµ­ì–´ ëœ» ì „ì²˜ë¦¬ - ê´„í˜¸ ë° ê´„í˜¸ ë‚´ìš© ì™„ì „ ì œê±°"""
    if not text:
        return ""
    s = normalize_spaces(text)

    # ë¬¼ê²° í‘œì‹œ(~)ë¥¼ 'ë¬´ì—‡ë¬´ì—‡'ìœ¼ë¡œ ì¹˜í™˜
    s = s.replace("~", "ë¬´ì—‡ë¬´ì—‡")

    # í’ˆì‚¬ ì•½ì–´ ì œê±° (ë¨¼ì € ì²˜ë¦¬)
    s = re.sub(r"\b(?:exp|pron|n|v|adj|adv|prep|conj|int|interj|aux|det|num)\.\s*", "", s, flags=re.I)
    s = re.sub(r"\b(?:ëª…ì‚¬|ë™ì‚¬|í˜•ìš©ì‚¬|ë¶€ì‚¬|ê°íƒ„ì‚¬|ëŒ€ëª…ì‚¬|ì „ì¹˜ì‚¬|ì ‘ì†ì‚¬|ì¡°ë™ì‚¬|ê´€ì‚¬|ìˆ˜ì‚¬)\.\s*", "", s)

    # ê´„í˜¸ ë° ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì™„ì „íˆ ì œê±° (ëª¨ë“  ì¢…ë¥˜ì˜ ê´„í˜¸)
    s = re.sub(r"[ï¼ˆ(ã€\[]([^ï¼‰)ã€‘\]]*)[ï¼‰)ã€‘\]]", "", s)

    # ì¶”ê°€ì ì¸ ê´„í˜¸ í˜•íƒœ ì œê±°
    s = re.sub(r"[ï¼ˆ(][^ï¼‰)]*[ï¼‰)]", "", s)
    s = re.sub(r"ã€[^ã€‘]*ã€‘", "", s)
    s = re.sub(r"\[[^\]]*\]", "", s)

    # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    s = re.sub(r"[/\\|<>\"']", " ", s)

    # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì •ë¦¬í•˜ê³  ì•ë’¤ ê³µë°± ì œê±°
    s = normalize_spaces(s).strip(" ;,Â·")
    return s

def clean_japanese_text(text: str) -> str:
    """ì¼ë³¸ì–´ í…ìŠ¤íŠ¸ ì •ë¦¬"""
    if not text:
        return ""
    s = normalize_spaces(text)
    s = re.sub(r"[ï¼ˆ(][^ï¼‰)]*[ï¼‰)]", "", s)  # ê´„í˜¸ ì œê±°
    s = re.sub(r"[/\\|<>\"']", " ", s)     # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    return normalize_spaces(s)

# ===== ì„±ë³„ ìˆœí™˜ =====
def is_male(index_zero_based: int) -> bool:
    return index_zero_based % 2 == 0

def voices_for_index(idx0: int) -> Dict[str, str]:
    """ì¸ë±ìŠ¤ë³„ ë³´ì´ìŠ¤ ì„ íƒ"""
    if is_male(idx0):
        return {"ja": JA_MALE, "ko": KO_MALE, "gender": "male"}
    else:
        return {"ja": JA_FEMALE, "ko": KO_FEMALE, "gender": "female"}

# ===== TTS =====
def tts_client() -> texttospeech.TextToSpeechClient:
    return texttospeech.TextToSpeechClient()

def synthesize_lang(
    tts: texttospeech.TextToSpeechClient, text: str, voice_name: str, language_code: str
) -> Optional[AudioSegment]:
    """ë‹¨ì¼ ì–¸ì–´ TTS í•©ì„±"""
    text = normalize_spaces(text)
    if not text:
        return AudioSegment.silent(duration=0)

    voice = texttospeech.VoiceSelectionParams(language_code=language_code, name=voice_name)
    cfg = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)
    inp = texttospeech.SynthesisInput(text=text)

    for attempt in range(1, MAX_RETRY + 2):
        try:
            resp = tts.synthesize_speech(input=inp, voice=voice, audio_config=cfg)
            seg = AudioSegment.from_file(BytesIO(resp.audio_content), format="mp3")
            return loudness_normalize(seg, TARGET_DBFS)
        except Exception as e:
            if attempt <= MAX_RETRY:
                time.sleep(RETRY_BACKOFF_SEC * attempt)
            else:
                print(f"  âŒ TTS ì‹¤íŒ¨(name={voice_name}, lang={language_code}): {e}")
                return None
    return None

def synthesize_lang_try_voices(
    tts: texttospeech.TextToSpeechClient,
    text: str,
    language_code: str,
    voices: List[str],
) -> Optional[AudioSegment]:
    """ë³´ì´ìŠ¤ í›„ë³´ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœì°¨ ì‹œë„"""
    for idx, vname in enumerate([v for v in voices if v]):
        seg = synthesize_lang(tts, text, vname, language_code)
        if seg is not None and len(seg) > 0:
            if idx > 0:
                print(f"  â†ªï¸ ëŒ€ì²´ ë³´ì´ìŠ¤ ì‚¬ìš©: {vname}")
            return seg
    print(f"  âŒ ëª¨ë“  ë³´ì´ìŠ¤ ì‹¤íŒ¨: {', '.join(voices)}")
    return None

def synthesize_with_commas_try_voices(
    tts: texttospeech.TextToSpeechClient,
    text: str,
    language_code: str,
    comma_gap_ms: int,
    voices: List[str],
) -> Optional[AudioSegment]:
    """ì‰¼í‘œ ë¶„í•  í•©ì„±"""
    text = normalize_spaces(text)
    if not text:
        return AudioSegment.silent(duration=0)

    parts = [p.strip() for p in re.split(r"[,\uFF0C]", text) if p.strip()]

    for idx_voice, vname in enumerate([v for v in voices if v]):
        silence = AudioSegment.silent(duration=comma_gap_ms)
        merged = AudioSegment.empty()
        ok = True

        for idx, part in enumerate(parts):
            seg = synthesize_lang(tts, part, vname, language_code)
            if seg is None or len(seg) == 0:
                ok = False
                break
            merged += seg
            if idx != len(parts) - 1:
                merged += silence

        if ok:
            if idx_voice > 0:
                print(f"  â†ªï¸ ëŒ€ì²´ ë³´ì´ìŠ¤ ì‚¬ìš©: {vname}")
            return loudness_normalize(merged, TARGET_DBFS)

    print(f"  âŒ ì‰¼í‘œ ë¶„í•  í•©ì„± ì‹¤íŒ¨: {', '.join(voices)}")
    return None

# ===== IO =====
def load_items(json_path: str) -> List[Dict[str, Any]]:
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    return data if isinstance(data, list) else [data]

def find_existing_gloss_files() -> List[str]:
    """ê¸°ì¡´ gloss.mp3 íŒŒì¼ë“¤ ì°¾ê¸°"""
    pattern = "jlpt/n5/*/gloss.mp3"
    files = glob.glob(pattern)
    print(f"ğŸ” ê¸°ì¡´ gloss.mp3 íŒŒì¼ {len(files)}ê°œ ë°œê²¬")
    return files

def sanitize_filename(name: str) -> str:
    name = re.sub(r'[\\/*?:"<>|]', "", str(name or ""))
    return name.strip().lower() or "unnamed"

# ===== ë©”ì¸ íŒŒì´í”„ë¼ì¸ =====
def process_gloss_only(json_path: str) -> None:
    try:
        items = load_items(json_path)
    except Exception as e:
        print(f"JSON ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    try:
        tts = tts_client()
    except Exception as e:
        print("Google Cloud ì¸ì¦ ì‹¤íŒ¨ ë˜ëŠ” í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨:", e)
        return

    # ê¸°ì¡´ gloss.mp3 íŒŒì¼ë“¤ í™•ì¸
    existing_files = find_existing_gloss_files()

    # romaji -> item ë§¤í•‘ ìƒì„±
    romaji_to_item = {}
    for i, item in enumerate(items):
        romaji = item.get("romaji", "")
        if romaji:
            romaji_to_item[sanitize_filename(romaji)] = (i, item)

    total = len(items)
    print(f"ğŸ§ JLPT gloss.mp3 ì¬ìƒì„± ì‹œì‘ (items={total})")
    print(f"    JA: male={JA_MALE}, female={JA_FEMALE} (ê¸°ì¡´ Chirp3 ìœ ì§€)")
    print(f"    KO: male={KO_MALE}, female={KO_FEMALE} (Neural12ë¡œ ë³€ê²½)")
    print(f"    gaps: gloss={GLOSS_GAP_MS}ms, comma={COMMA_GAP_MS}ms")
    print(f"    ê´„í˜¸ ì²˜ë¦¬: í•œêµ­ì–´ì—ì„œ ê´„í˜¸ ë° ë‚´ìš© ì™„ì „ ì œê±°\n")

    processed = 0
    success = 0
    fails: List[str] = []

    for i, item in enumerate(items):
        lemma = item.get("lemma", "")
        kana = item.get("kana", "")
        romaji = item.get("romaji", "")
        ko_gloss_raw = item.get("koGloss", "") or item.get("koChirpScript", "")

        if not lemma or not kana or not romaji or not ko_gloss_raw:
            print(f"[{i+1}/{total}] ê±´ë„ˆëœ€: í•„ìˆ˜ í•„ë“œ ëˆ„ë½ â†’ {romaji}")
            continue

        # ì¶œë ¥ ê²½ë¡œ í™•ì¸
        word_folder = sanitize_filename(romaji)
        out_dir = os.path.normpath(os.path.join("jlpt", "n5", word_folder))
        gloss_path = os.path.join(out_dir, "gloss.mp3")
        word_path = os.path.join(out_dir, "word.mp3")

        # ê¸°ì¡´ word.mp3ê°€ ìˆëŠ”ì§€ í™•ì¸ (ì—†ìœ¼ë©´ ê±´ë„ˆëœ€)
        if not os.path.exists(word_path):
            print(f"[{i+1}/{total}] ê±´ë„ˆëœ€: word.mp3 ì—†ìŒ â†’ {word_path}")
            continue

        processed += 1
        v = voices_for_index(i)
        print(f"[{processed}] '{lemma}({kana})' â†’ {gloss_path}")
        print(f"    ja={v['ja']}, ko={v['ko']} (gender={v['gender']})")

        # ê¸°ì¡´ word.mp3 ë¡œë“œ
        try:
            word_seg = AudioSegment.from_mp3(word_path)
            word_seg = loudness_normalize(word_seg, TARGET_DBFS)
        except Exception as e:
            print(f"  âŒ word.mp3 ë¡œë“œ ì‹¤íŒ¨: {e}")
            fails.append(f"{romaji}\tWORD_LOAD_FAIL:{e}")
            continue

        # í•œêµ­ì–´ ëœ» ì •ë¦¬ (ê´„í˜¸ ì™„ì „ ì œê±°)
        ko_gloss = clean_ko_gloss_strict(ko_gloss_raw)
        if not ko_gloss:
            print(f"  âš ï¸ í•œêµ­ì–´ ëœ» ë¹„ì–´ìˆìŒ: '{ko_gloss_raw}'")
            fails.append(f"{romaji}\tEMPTY_KOGLOSS")
            continue

        print(f"    ì›ë³¸: '{ko_gloss_raw}'")
        print(f"    ì •ë¦¬: '{ko_gloss}'")

        # í•œêµ­ì–´ ìŒì„± í•©ì„± (ì½¤ë§ˆ ë¶„í•  ì ìš©)
        ko_candidates = [v["ko"]] + (
            KO_MALE_FALLBACKS if v["gender"] == "male" else KO_FEMALE_FALLBACKS
        )
        ko_seg = synthesize_with_commas_try_voices(
            tts, ko_gloss, "ko-KR", COMMA_GAP_MS, ko_candidates
        )

        if ko_seg is None or len(ko_seg) == 0:
            print("  âŒ í•œêµ­ì–´ ìŒì„± í•©ì„± ì‹¤íŒ¨")
            fails.append(f"{romaji}\tKO_SYNTH_FAIL")
            continue

        # gloss.mp3 ì¡°í•©: word + 1ì´ˆ ë¬´ìŒ + í•œêµ­ì–´
        gloss_seg = word_seg + AudioSegment.silent(duration=GLOSS_GAP_MS) + ko_seg
        gloss_seg = loudness_normalize(gloss_seg, TARGET_DBFS)

        # ì €ì¥
        try:
            os.makedirs(out_dir, exist_ok=True)
            gloss_seg.export(gloss_path, format="mp3")
            print(f"  âœ… gloss.mp3 êµì²´ ì™„ë£Œ")
            success += 1
        except Exception as e:
            print(f"  âŒ gloss.mp3 ì €ì¥ ì‹¤íŒ¨: {e}")
            fails.append(f"{romaji}\tGLOSS_SAVE_FAIL:{e}")

    # ê²°ê³¼ ì •ë¦¬
    print(f"\nğŸ“Š ì²˜ë¦¬ ì™„ë£Œ:")
    print(f"    ì²˜ë¦¬ ëŒ€ìƒ: {processed}ê°œ")
    print(f"    ì„±ê³µ: {success}ê°œ")
    print(f"    ì‹¤íŒ¨: {len(fails)}ê°œ")

    if fails:
        with open("gloss_ì¬ìƒì„±_ì‹¤íŒ¨_ëª©ë¡.txt", "w", encoding="utf-8") as f:
            f.write("\n".join(fails) + "\n")
        print(f"âš ï¸ ì‹¤íŒ¨ ëª©ë¡ â†’ 'gloss_ì¬ìƒì„±_ì‹¤íŒ¨_ëª©ë¡.txt' ì €ì¥")
    else:
        print("âœ… ëª¨ë“  gloss.mp3 íŒŒì¼ ì¬ìƒì„± ì™„ë£Œ!")

if __name__ == "__main__":
    json_file = sys.argv[1] if len(sys.argv) > 1 else "jlpt_n5_vocabs.json"
    if not os.path.exists(json_file):
        print(f"âŒ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_file}")
        sys.exit(1)

    print(f"ğŸ“‚ ì‚¬ìš©í•  JSON íŒŒì¼: {json_file}")
    process_gloss_only(json_file)