import React, {useState, useEffect, useRef} from 'react';
import {
  View,
  Text,
  TouchableOpacity,
  StyleSheet,
  Alert,
  Animated,
  Dimensions,
} from 'react-native';
import {useTheme} from '../context/ThemeContext';
import VoiceRecordingService, {
  RecordingProgress,
  PlaybackProgress,
  RecordingResult,
} from '../services/VoiceRecordingService';
import WaveformVisualization from './WaveformVisualization';

interface PronunciationPracticeProps {
  text: string;
  targetLanguage: 'english' | 'korean' | 'japanese' | 'chinese';
  onComplete?: (result: PronunciationResult) => void;
  showWaveform?: boolean;
  maxRecordingTime?: number; // in milliseconds
}

export interface PronunciationResult {
  recordingUri: string;
  duration: number;
  quality: 'poor' | 'fair' | 'good' | 'excellent';
  score: number;
  feedback: string[];
  amplitudeData: number[];
}

export const PronunciationPractice: React.FC<PronunciationPracticeProps> = ({
  text,
  targetLanguage,
  onComplete,
  showWaveform = true,
  maxRecordingTime = 30000, // 30 seconds default
}) => {
  const {colors} = useTheme();
  const [isRecording, setIsRecording] = useState(false);
  const [isPlaying, setIsPlaying] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const [playbackTime, setPlaybackTime] = useState(0);
  const [playbackDuration, setPlaybackDuration] = useState(0);
  const [currentRecording, setCurrentRecording] = useState<RecordingResult | null>(null);
  const [amplitudeData, setAmplitudeData] = useState<number[]>([]);
  const [isAnalyzing, setIsAnalyzing] = useState(false);
  
  const recordButtonScale = useRef(new Animated.Value(1)).current;
  const recordingTimer = useRef<NodeJS.Timeout | null>(null);
  
  useEffect(() => {
    return () => {
      // Cleanup on unmount
      VoiceRecordingService.cleanup();
      if (recordingTimer.current) {
        clearTimeout(recordingTimer.current);
      }
    };
  }, []);

  const startRecording = async () => {
    try {
      setIsRecording(true);
      setRecordingTime(0);
      setAmplitudeData([]);

      // Animate record button
      Animated.spring(recordButtonScale, {
        toValue: 1.2,
        useNativeDriver: true,
      }).start();

      await VoiceRecordingService.startRecording((progress: RecordingProgress) => {
        setRecordingTime(progress.currentPosition);
        
        // Update amplitude data for waveform
        if (progress.currentMetering !== undefined) {
          setAmplitudeData(prev => [...prev, progress.currentMetering!]);
        }
      });

      // Auto-stop after max time
      recordingTimer.current = setTimeout(() => {
        if (isRecording) {
          stopRecording();
        }
      }, maxRecordingTime);

    } catch (error) {
      console.error('Failed to start recording:', error);
      setIsRecording(false);
      Alert.alert('ÎÖπÏùå Ïò§Î•ò', 'ÎÖπÏùåÏùÑ ÏãúÏûëÌï† Ïàò ÏóÜÏäµÎãàÎã§. ÎßàÏù¥ÌÅ¨ Í∂åÌïúÏùÑ ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.');
    }
  };

  const stopRecording = async () => {
    try {
      if (recordingTimer.current) {
        clearTimeout(recordingTimer.current);
        recordingTimer.current = null;
      }

      const result = await VoiceRecordingService.stopRecording();
      setCurrentRecording(result);
      setIsRecording(false);

      // Reset button animation
      Animated.spring(recordButtonScale, {
        toValue: 1,
        useNativeDriver: true,
      }).start();

      // Get final amplitude data
      const finalAmplitudeData = VoiceRecordingService.getAmplitudeData();
      setAmplitudeData(finalAmplitudeData);

      // Auto-analyze if callback provided
      if (onComplete) {
        await analyzeRecording(result, finalAmplitudeData);
      }

    } catch (error) {
      console.error('Failed to stop recording:', error);
      setIsRecording(false);
      Alert.alert('ÎÖπÏùå Ïò§Î•ò', 'ÎÖπÏùåÏùÑ Ï§ëÏßÄÌïòÎäîÎç∞ Ïã§Ìå®ÌñàÏäµÎãàÎã§.');
    }
  };

  const playRecording = async () => {
    if (!currentRecording) return;

    try {
      setIsPlaying(true);
      await VoiceRecordingService.startPlayback(
        currentRecording.uri,
        (progress: PlaybackProgress) => {
          setPlaybackTime(progress.currentPosition);
          setPlaybackDuration(progress.duration);
        }
      );
    } catch (error) {
      console.error('Failed to play recording:', error);
      setIsPlaying(false);
      Alert.alert('Ïû¨ÏÉù Ïò§Î•ò', 'ÎÖπÏùåÏùÑ Ïû¨ÏÉùÌï† Ïàò ÏóÜÏäµÎãàÎã§.');
    }
  };

  const stopPlayback = async () => {
    try {
      await VoiceRecordingService.stopPlayback();
      setIsPlaying(false);
      setPlaybackTime(0);
    } catch (error) {
      console.error('Failed to stop playback:', error);
    }
  };

  const analyzeRecording = async (recording: RecordingResult, amplitudes: number[]) => {
    if (!onComplete) return;

    setIsAnalyzing(true);
    
    try {
      const quality = await VoiceRecordingService.getRecordingQuality(recording.uri);
      const analysis = await VoiceRecordingService.analyzeVoice(recording.uri);

      // Generate feedback based on analysis
      const feedback = generateFeedback(quality, analysis, targetLanguage);

      const result: PronunciationResult = {
        recordingUri: recording.uri,
        duration: recording.duration,
        quality: quality.quality,
        score: quality.score,
        feedback,
        amplitudeData: amplitudes,
      };

      onComplete(result);
    } catch (error) {
      console.error('Failed to analyze recording:', error);
      Alert.alert('Î∂ÑÏÑù Ïò§Î•ò', 'Î∞úÏùå Î∂ÑÏÑùÏóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.');
    } finally {
      setIsAnalyzing(false);
    }
  };

  const generateFeedback = (
    quality: any,
    analysis: any,
    language: string
  ): string[] => {
    const feedback: string[] = [];

    // Quality-based feedback
    if (quality.quality === 'poor') {
      feedback.push('ÏùåÏßàÏù¥ Ï¢ãÏßÄ ÏïäÏäµÎãàÎã§. ÎßàÏù¥ÌÅ¨Ïóê Îçî Í∞ÄÍπåÏù¥ ÎßêÌï¥Î≥¥ÏÑ∏Ïöî.');
    } else if (quality.quality === 'excellent') {
      feedback.push('ÌõåÎ•≠Ìïú ÏùåÏßàÏûÖÎãàÎã§!');
    }

    // Volume-based feedback
    if (analysis.volume < 0.3) {
      feedback.push('Îçî ÌÅ¨Í≤å ÎßêÌï¥Î≥¥ÏÑ∏Ïöî.');
    } else if (analysis.volume > 0.8) {
      feedback.push('Ï°∞Í∏à Îçî Î∂ÄÎìúÎüΩÍ≤å ÎßêÌï¥Î≥¥ÏÑ∏Ïöî.');
    }

    // Language-specific feedback
    switch (language) {
      case 'english':
        feedback.push('ÏòÅÏñ¥ Î∞úÏùå Ïó∞Ïäµ ÏôÑÎ£å! ÏûêÏó∞Ïä§Îü¨Ïö¥ ÏñµÏñëÏúºÎ°ú ÎßêÌï¥Î≥¥ÏÑ∏Ïöî.');
        break;
      case 'korean':
        feedback.push('ÌïúÍµ≠Ïñ¥ Î∞úÏùåÏù¥ Ï¢ãÏäµÎãàÎã§. Î∞õÏπ® Î∞úÏùåÏóê Ï£ºÏùòÌï¥Î≥¥ÏÑ∏Ïöî.');
        break;
      case 'japanese':
        feedback.push('ÏùºÎ≥∏Ïñ¥ Î∞úÏùå Ïó∞Ïäµ ÏôÑÎ£å! Ïû•Îã®ÏùåÏóê Ï£ºÏùòÌï¥Î≥¥ÏÑ∏Ïöî.');
        break;
      case 'chinese':
        feedback.push('Ï§ëÍµ≠Ïñ¥ ÏÑ±Ï°∞Ïóê Ï£ºÏùòÌïòÎ©∞ Îã§Ïãú Ïó∞ÏäµÌï¥Î≥¥ÏÑ∏Ïöî.');
        break;
    }

    return feedback;
  };

  const deleteRecording = async () => {
    if (!currentRecording) return;

    try {
      await VoiceRecordingService.deleteRecording(currentRecording.uri);
      setCurrentRecording(null);
      setAmplitudeData([]);
      setPlaybackTime(0);
      setPlaybackDuration(0);
    } catch (error) {
      console.error('Failed to delete recording:', error);
    }
  };

  const getLanguageFlag = (language: string): string => {
    const flags = {
      english: 'üá∫üá∏',
      korean: 'üá∞üá∑',
      japanese: 'üáØüáµ',
      chinese: 'üá®üá≥',
    };
    return flags[language as keyof typeof flags] || 'üåç';
  };

  const formatTime = (milliseconds: number): string => {
    return VoiceRecordingService.formatTime(milliseconds);
  };

  const styles = StyleSheet.create({
    container: {
      backgroundColor: colors.surface,
      borderRadius: 16,
      padding: 20,
      margin: 16,
      shadowColor: '#000',
      shadowOffset: {width: 0, height: 4},
      shadowOpacity: 0.1,
      shadowRadius: 8,
      elevation: 5,
    },
    header: {
      flexDirection: 'row',
      alignItems: 'center',
      marginBottom: 16,
    },
    languageFlag: {
      fontSize: 24,
      marginRight: 12,
    },
    title: {
      fontSize: 18,
      fontWeight: '600',
      color: colors.text,
      flex: 1,
    },
    textContainer: {
      backgroundColor: colors.background,
      borderRadius: 12,
      padding: 16,
      marginBottom: 20,
      borderLeftWidth: 4,
      borderLeftColor: colors.primary,
    },
    practiceText: {
      fontSize: 16,
      lineHeight: 24,
      color: colors.text,
      textAlign: 'center',
    },
    controlsContainer: {
      alignItems: 'center',
      marginBottom: showWaveform ? 20 : 0,
    },
    recordButton: {
      width: 80,
      height: 80,
      borderRadius: 40,
      justifyContent: 'center',
      alignItems: 'center',
      marginBottom: 16,
      shadowColor: '#000',
      shadowOffset: {width: 0, height: 2},
      shadowOpacity: 0.2,
      shadowRadius: 4,
      elevation: 3,
    },
    recordButtonRecording: {
      backgroundColor: colors.error,
    },
    recordButtonNormal: {
      backgroundColor: colors.primary,
    },
    recordButtonIcon: {
      fontSize: 32,
    },
    timer: {
      fontSize: 18,
      fontWeight: '600',
      color: colors.text,
      marginBottom: 16,
    },
    playbackControls: {
      flexDirection: 'row',
      alignItems: 'center',
      justifyContent: 'center',
      gap: 16,
    },
    controlButton: {
      width: 48,
      height: 48,
      borderRadius: 24,
      backgroundColor: colors.secondary,
      justifyContent: 'center',
      alignItems: 'center',
    },
    controlButtonText: {
      fontSize: 20,
    },
    playbackTime: {
      fontSize: 14,
      color: colors.secondaryText,
      minWidth: 80,
      textAlign: 'center',
    },
    analysisContainer: {
      marginTop: 16,
      padding: 16,
      backgroundColor: colors.info + '10',
      borderRadius: 12,
      borderWidth: 1,
      borderColor: colors.info + '30',
    },
    analysisText: {
      fontSize: 16,
      fontWeight: '600',
      color: colors.text,
      textAlign: 'center',
    },
    waveformContainer: {
      marginTop: 16,
      height: 80,
      backgroundColor: colors.background,
      borderRadius: 8,
      overflow: 'hidden',
    },
    actionButtons: {
      flexDirection: 'row',
      justifyContent: 'space-between',
      marginTop: 16,
      gap: 12,
    },
    actionButton: {
      flex: 1,
      paddingVertical: 12,
      paddingHorizontal: 16,
      borderRadius: 8,
      alignItems: 'center',
    },
    retryButton: {
      backgroundColor: colors.warning,
    },
    deleteButton: {
      backgroundColor: colors.error,
    },
    actionButtonText: {
      fontSize: 14,
      fontWeight: '600',
      color: colors.onPrimary,
    },
    maxTimeWarning: {
      fontSize: 12,
      color: colors.warning,
      textAlign: 'center',
      marginTop: 8,
    },
  });

  return (
    <View style={styles.container}>
      <View style={styles.header}>
        <Text style={styles.languageFlag}>
          {getLanguageFlag(targetLanguage)}
        </Text>
        <Text style={styles.title}>Î∞úÏùå Ïó∞Ïäµ</Text>
      </View>

      <View style={styles.textContainer}>
        <Text style={styles.practiceText}>{text}</Text>
      </View>

      <View style={styles.controlsContainer}>
        <Animated.View style={{transform: [{scale: recordButtonScale}]}}>
          <TouchableOpacity
            style={[
              styles.recordButton,
              isRecording ? styles.recordButtonRecording : styles.recordButtonNormal,
            ]}
            onPress={isRecording ? stopRecording : startRecording}
            disabled={isAnalyzing}>
            <Text style={styles.recordButtonIcon}>
              {isRecording ? '‚èπÔ∏è' : 'üé§'}
            </Text>
          </TouchableOpacity>
        </Animated.View>

        <Text style={styles.timer}>
          {formatTime(isRecording ? recordingTime : playbackTime)}
          {playbackDuration > 0 && ` / ${formatTime(playbackDuration)}`}
        </Text>

        {!isRecording && recordingTime < maxRecordingTime * 0.9 && (
          <Text style={styles.maxTimeWarning}>
            ÏµúÎåÄ ÎÖπÏùå ÏãúÍ∞Ñ: {formatTime(maxRecordingTime)}
          </Text>
        )}

        {currentRecording && (
          <View style={styles.playbackControls}>
            <TouchableOpacity
              style={styles.controlButton}
              onPress={isPlaying ? stopPlayback : playRecording}>
              <Text style={styles.controlButtonText}>
                {isPlaying ? '‚èπÔ∏è' : '‚ñ∂Ô∏è'}
              </Text>
            </TouchableOpacity>
          </View>
        )}
      </View>

      {showWaveform && amplitudeData.length > 0 && (
        <View style={styles.waveformContainer}>
          <WaveformVisualization
            data={amplitudeData}
            color={colors.primary}
            isRecording={isRecording}
          />
        </View>
      )}

      {isAnalyzing && (
        <View style={styles.analysisContainer}>
          <Text style={styles.analysisText}>üîç Î∞úÏùå Î∂ÑÏÑù Ï§ë...</Text>
        </View>
      )}

      {currentRecording && (
        <View style={styles.actionButtons}>
          <TouchableOpacity
            style={[styles.actionButton, styles.retryButton]}
            onPress={() => {
              deleteRecording();
              startRecording();
            }}>
            <Text style={styles.actionButtonText}>Îã§Ïãú ÎÖπÏùå</Text>
          </TouchableOpacity>
          <TouchableOpacity
            style={[styles.actionButton, styles.deleteButton]}
            onPress={deleteRecording}>
            <Text style={styles.actionButtonText}>ÏÇ≠Ï†ú</Text>
          </TouchableOpacity>
        </View>
      )}
    </View>
  );
};