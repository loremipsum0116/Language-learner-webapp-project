# make_word_gloss.py
# -*- coding: utf-8 -*-
"""
JSON(Î∞∞Ïó¥/Îã®Ïùº)Î°úÎ∂ÄÌÑ∞ <level>/<lemma>/{word,gloss}.mp3 ÏÉùÏÑ±(Ìï≠ÏÉÅ ÎçÆÏñ¥Ïì∞Í∏∞).

ÏöîÍµ¨ÏÇ¨Ìï≠:
- Î≥¥Ïù¥Ïä§: Î™®Îì† Ìï©ÏÑ±(en/KR Î™®Îëê) en-US(Chirp3 HD) ÏÇ¨Ïö©.
  - ÎÇ®ÏÑ±: en-US-Chirp3-HD-Charon
  - Ïó¨ÏÑ±: en-US-Chirp3-HD-Laomedeia
  - Ìï≠Î™©Î≥Ñ ÏàúÌôò: ÎÇ® ‚Üí Ïó¨ ‚Üí ÎÇ® ‚Üí Ïó¨ ...
- word.mp3: lemma(ÏòÅÎ¨∏) Ìï©ÏÑ±
- gloss.mp3: word.mp3 + GLOSS_GAP_MS Î¨¥Ïùå + koGloss(ÌïúÍµ≠Ïñ¥ Neural2) Ìï©ÏÑ±
  - Charon(ÏòÅÎ¨∏ ÎÇ®ÏÑ±) ‚Üí ÌïúÍµ≠Ïñ¥ ÎÇ®ÏÑ±(Í∏∞Î≥∏: ko-KR-Neural2-C)
  - Laomedeia(ÏòÅÎ¨∏ Ïó¨ÏÑ±) ‚Üí ÌïúÍµ≠Ïñ¥ Ïó¨ÏÑ±(Í∏∞Î≥∏: ko-KR-Neural2-B)
  - koGloss ÎÇ¥ '~' ‚Üí 'Î¨¥ÏóáÎ¨¥Ïóá'
  - koGloss ÎÇ¥ ÏâºÌëú(,)ÎßàÎã§ COMMA_GAP_MS Î¨¥Ïùå ÏÇΩÏûÖ
- Î†àÎ≤® Ìè¥Îçî: 'ÏûÖÎ¨∏'‚Üístarter, 'Í∏∞Ï¥à'‚Üíelementary, 'Ï§ëÍ∏â'‚Üíintermediate, 'Ï§ëÏÉÅÍ∏â'‚Üíupper, 'Í≥†Í∏â'‚Üíadvanced
- Í∏∞Ï°¥ ÌååÏùºÏùÄ Ìï≠ÏÉÅ ÎçÆÏñ¥Ïì∞Í∏∞.

ÌïÑÏàò: pip install google-cloud-texttospeech pydub, FFmpeg, GCP ADC
ÌôòÍ≤ΩÎ≥ÄÏàò(ÏòµÏÖò):
  TARGET_DBFS=-16.0, GLOSS_GAP_MS=1000, COMMA_GAP_MS=500, MAX_RETRY=2, RETRY_BACKOFF_SEC=0.8
  EN_MALE, EN_FEMALE, KO_MALE_NEURAL, KO_FEMALE_NEURAL                 # ÏùºÎ∞ò ÎÇ®/Ïó¨ Í∏∞Î≥∏Í∞í
  KO_NEURAL_FOR_CHARON, KO_NEURAL_FOR_LAOMEDEIA                         # ÏòÅÎ¨∏ Î≥¥Ïù¥Ïä§Î≥Ñ Í∞ïÏ†ú Îß§Ìïë(Ïö∞ÏÑ†)
  KO_MALE_FALLBACKS, KO_FEMALE_FALLBACKS                                # Ìï©ÏÑ± Ïã§Ìå® Ïãú ÌïúÍµ≠Ïñ¥ Ìè¥Î∞± ÌõÑÎ≥¥(ÏâºÌëú Íµ¨Î∂Ñ)
"""

import os
os.environ["GRPC_DNS_RESOLVER"] = "native"

import sys, re, json, time
from io import BytesIO
from typing import Any, Dict, List, Optional

from google.cloud import texttospeech
from pydub import AudioSegment

# ===== ÌååÎùºÎØ∏ÌÑ∞ =====
TARGET_DBFS = float(os.getenv("TARGET_DBFS", "-16.0"))
GLOSS_GAP_MS = int(os.getenv("GLOSS_GAP_MS", "1000"))   # word‚ÜíkoGloss Í∞ÑÍ≤©(Í∏∞Î≥∏ 1.0Ï¥à)
COMMA_GAP_MS = int(os.getenv("COMMA_GAP_MS", "500"))    # koGloss ÎÇ¥ ÏΩ§Îßà Í∞ÑÍ≤©(Í∏∞Î≥∏ 0.5Ï¥à)
MAX_RETRY = int(os.getenv("MAX_RETRY", "2"))
RETRY_BACKOFF_SEC = float(os.getenv("RETRY_BACKOFF_SEC", "0.8"))

# en-US(Chirp3 HD)
EN_MALE   = os.getenv("EN_MALE", "en-US-Chirp3-HD-Charon")
EN_FEMALE = os.getenv("EN_FEMALE", "en-US-Chirp3-HD-Laomedeia")

# ko-KR(Neural2) Í∏∞Î≥∏Í∞í
# Ï£º: ÏÑúÎπÑÏä§ ÏßÄÏó≠/ÌîÑÎ°úÏ†ùÌä∏Î≥ÑÎ°ú Ï°¥Ïû¨ Î≥¥Ïù¥Ïä§Í∞Ä Îã§Î•º Ïàò ÏûàÏäµÎãàÎã§.
KO_MALE_NEURAL   = os.getenv("KO_MALE_NEURAL",   "ko-KR-Neural2-C")  # ÎÇ®ÏÑ± Í∏∞Î≥∏(Í¥ëÎ≤îÏúÑÌïòÍ≤å Ï°¥Ïû¨)
KO_FEMALE_NEURAL = os.getenv("KO_FEMALE_NEURAL", "ko-KR-Neural2-B")  # Ïó¨ÏÑ± Í∏∞Î≥∏

# ÏòÅÎ¨∏ Î≥¥Ïù¥Ïä§Î™Ö Í∏∞Î∞ò Í∞ïÏ†ú Îß§Ìïë(ÏµúÏö∞ÏÑ†)
KO_NEURAL_FOR_CHARON    = os.getenv("KO_NEURAL_FOR_CHARON",    "ko-KR-Neural2-C")  # ÎÇ®ÏÑ±
KO_NEURAL_FOR_LAOMEDEIA = os.getenv("KO_NEURAL_FOR_LAOMEDEIA", "ko-KR-Neural2-B")  # Ïó¨ÏÑ±

# Ìè¥Î∞± ÌõÑÎ≥¥(ÏâºÌëúÎ°ú Íµ¨Î∂Ñ; ÏôºÏ™ΩÎ∂ÄÌÑ∞ ÏãúÎèÑ)
def _parse_list(s: str) -> List[str]:
    return [x.strip() for x in s.split(",") if x.strip()]

KO_MALE_FALLBACKS   = _parse_list(os.getenv("KO_MALE_FALLBACKS",
                                            "ko-KR-Neural2-C,ko-KR-Neural2-B,ko-KR-Neural2-A,ko-KR-Standard-D,ko-KR-Standard-C"))
KO_FEMALE_FALLBACKS = _parse_list(os.getenv("KO_FEMALE_FALLBACKS",
                                            "ko-KR-Neural2-B,ko-KR-Neural2-A,ko-KR-Standard-A,ko-KR-Standard-B"))

LEVEL_MAP = [
    ("Í≥†Í∏â",   "advanced"),
    ("Ï§ëÏÉÅÍ∏â", "upper"),
    ("Ï§ëÍ∏â",   "intermediate"),
    ("Í∏∞Ï¥à",   "elementary"),
    ("ÏûÖÎ¨∏",   "starter"),
]

# ===== Ïú†Ìã∏ =====
def normalize_spaces(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").strip())

def sanitize_filename(name: str) -> str:
    name = re.sub(r'[\\/*?:"<>|]', "", str(name or ""))
    return name.strip().lower() or "unnamed"

def loudness_normalize(seg: AudioSegment, target_dbfs: float) -> AudioSegment:
    if seg.duration_seconds <= 0 or seg.dBFS == float("-inf"):
        return seg
    return seg.apply_gain(target_dbfs - seg.dBFS)

def level_folder_from_categories(categories: Any) -> Optional[str]:
    if isinstance(categories, list):
        cat_str = ",".join(map(str, categories))
    elif isinstance(categories, str):
        cat_str = categories
    else:
        cat_str = str(categories or "")
    for kr, folder in LEVEL_MAP:
        if kr in cat_str:
            return folder
    return None

def build_output_paths(categories: Any, lemma: str) -> Dict[str, str]:
    level = level_folder_from_categories(categories)
    if level is None:
        raise ValueError("LEVEL_TAG_MISSING")
    word_folder = sanitize_filename(lemma)
    out_dir = os.path.normpath(os.path.join(level, word_folder))
    os.makedirs(out_dir, exist_ok=True)
    return {
        "dir": out_dir,
        "word": os.path.join(out_dir, "word.mp3"),
        "gloss": os.path.join(out_dir, "gloss.mp3"),
    }

def clean_ko_gloss(text: str) -> str:
    """
    koGloss Ï†ÑÏ≤òÎ¶¨:
      - '~' ‚Üí 'Î¨¥ÏóáÎ¨¥Ïóá'
      - ÌíàÏÇ¨ ÏïΩÏñ¥ Ï†úÍ±∞(adj., n., art., ...)
      - Í≥µÎ∞±/Íµ¨ÎëêÏ†ê Ï†ïÎ¶¨
    """
    if not text:
        return ""
    s = normalize_spaces(text)
    s = s.replace("~", "Î¨¥ÏóáÎ¨¥Ïóá")
    s = re.sub(r"\b(?:adj|adv|n|v|vt|vi|prep|conj|pron|art|int|interj|aux|det|num)\.\s*", "", s, flags=re.I)
    s = normalize_spaces(s).strip(" ;,¬∑")
    return s

# ===== ÏÑ±Î≥Ñ ÏàúÌôò & Î≥¥Ïù¥Ïä§ Îß§Ìïë =====
def is_male(index_zero_based: int) -> bool:
    return (index_zero_based % 2 == 0)  # 0,2,4,... ÎÇ®ÏÑ± / 1,3,5,... Ïó¨ÏÑ±

def voices_for_index(idx0: int) -> Dict[str, str]:
    """
    1) en Î≥¥Ïù¥Ïä§Îäî Í∏∞Ï°¥ ÏàúÌôò Í∑úÏπô(ÎÇ®/Ïó¨)
    2) ko Î≥¥Ïù¥Ïä§Îäî en Î≥¥Ïù¥Ïä§Î™Ö(Charon/Laomedeia)Ïóê 'Í∞ïÏ†ú Îß§Ìïë' Ïö∞ÏÑ† Ï†ÅÏö©
       - Í∑∏ Ïô∏ en Î≥¥Ïù¥Ïä§Î™ÖÏùº ÎïåÎßå ÎÇ®/Ïó¨ Í∏∞Î≥∏Í∞í ÏÇ¨Ïö©
    """
    if is_male(idx0):
        en = EN_MALE
    else:
        en = EN_FEMALE

    if "Charon" in en:
        ko = KO_NEURAL_FOR_CHARON
        gender = "male"
    elif "Laomedeia" in en:
        ko = KO_NEURAL_FOR_LAOMEDEIA
        gender = "female"
    else:
        gender = "male" if is_male(idx0) else "female"
        ko = KO_MALE_NEURAL if gender == "male" else KO_FEMALE_NEURAL

    return {"en": en, "ko": ko, "gender": gender}

# ===== TTS =====
def tts_client() -> texttospeech.TextToSpeechClient:
    return texttospeech.TextToSpeechClient()

def synthesize_lang(tts: texttospeech.TextToSpeechClient,
                    text: str,
                    voice_name: str,
                    language_code: str) -> Optional[AudioSegment]:
    """Ï£ºÏñ¥ÏßÑ Ïñ∏Ïñ¥ÏΩîÎìú/Î≥¥Ïù¥Ïä§Î°ú Îã®Ïùº Ìï©ÏÑ±."""
    text = normalize_spaces(text)
    if not text:
        return AudioSegment.silent(duration=0)
    voice = texttospeech.VoiceSelectionParams(language_code=language_code, name=voice_name)
    cfg = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)
    inp = texttospeech.SynthesisInput(text=text)
    for attempt in range(1, MAX_RETRY + 2):
        try:
            resp = tts.synthesize_speech(input=inp, voice=voice, audio_config=cfg)
            seg = AudioSegment.from_file(BytesIO(resp.audio_content), format="mp3")
            return loudness_normalize(seg, TARGET_DBFS)
        except Exception as e:
            if attempt <= MAX_RETRY:
                time.sleep(RETRY_BACKOFF_SEC * attempt)
            else:
                # ÏµúÏ¢Ö Ïã§Ìå®
                print(f"  ‚ùå TTS Ïã§Ìå®(name={voice_name}, lang={language_code}): {e}")
                return None
    return None

def synthesize_lang_try_voices(tts: texttospeech.TextToSpeechClient,
                               text: str,
                               language_code: str,
                               voices: List[str]) -> Optional[AudioSegment]:
    """Î≥¥Ïù¥Ïä§ ÌõÑÎ≥¥ Î¶¨Ïä§Ìä∏Î•º ÏàúÏ∞® ÏãúÎèÑ."""
    last_err = None
    for idx, vname in enumerate([v for v in voices if v]):
        seg = synthesize_lang(tts, text, vname, language_code)
        if seg is not None and len(seg) > 0:
            if idx > 0:
                print(f"  ‚Ü™Ô∏é ÏÇ¨Ïö© Í∞ÄÎä• Î≥¥Ïù¥Ïä§Î°ú ÎåÄÏ≤¥: {vname}")
            return seg
        last_err = vname
    if last_err:
        print(f"  ‚ùå Î™®Îì† Î≥¥Ïù¥Ïä§ Ïã§Ìå®(ko candidates tried: {', '.join(voices)})")
    return None

def synthesize_with_commas_try_voices(tts: texttospeech.TextToSpeechClient,
                                      text: str,
                                      language_code: str,
                                      comma_gap_ms: int,
                                      voices: List[str]) -> Optional[AudioSegment]:
    """ÏâºÌëú Î∂ÑÌï† Ìï©ÏÑ±Ïóê ÎåÄÌï¥ Î≥¥Ïù¥Ïä§ ÌõÑÎ≥¥ Î¶¨Ïä§Ìä∏Î•º ÏàúÏ∞® ÏãúÎèÑ."""
    text = normalize_spaces(text)
    if not text:
        return AudioSegment.silent(duration=0)

    parts = [p.strip() for p in re.split(r"[,\uFF0C]", text) if p.strip()]
    for idx_voice, vname in enumerate([v for v in voices if v]):
        silence = AudioSegment.silent(duration=comma_gap_ms)
        merged = AudioSegment.empty()
        ok = True
        for idx, part in enumerate(parts):
            seg = synthesize_lang(tts, part, vname, language_code)
            if seg is None or len(seg) == 0:
                ok = False
                break
            merged += seg
            if idx != len(parts) - 1:
                merged += silence
        if ok:
            if idx_voice > 0:
                print(f"  ‚Ü™Ô∏é ko Î≥¥Ïù¥Ïä§ ÎåÄÏ≤¥: {vname}")
            return loudness_normalize(merged, TARGET_DBFS)
    print(f"  ‚ùå koGloss Ìï©ÏÑ± Ïã§Ìå®(ko candidates tried: {', '.join(voices)})")
    return None

# ===== IO =====
def load_items(json_path: str) -> List[Dict[str, Any]]:
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    return data if isinstance(data, list) else [data]

# ===== Î©îÏù∏ ÌååÏù¥ÌîÑÎùºÏù∏ =====
def process(json_path: str) -> None:
    try:
        items = load_items(json_path)
    except Exception as e:
        print(f"JSON Î°úÎìú Ïã§Ìå®: {e}")
        return

    try:
        tts = tts_client()
    except Exception as e:
        print("Google Cloud Ïù∏Ï¶ù Ïã§Ìå® ÎòêÎäî ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÉùÏÑ± Ïã§Ìå®:", e)
        return

    total = len(items)
    print(f"üéß Start (items={total})")
    print(f"    EN: male={EN_MALE}, female={EN_FEMALE}")
    print(f"    KO defaults: male={KO_MALE_NEURAL}, female={KO_FEMALE_NEURAL}")
    print(f"    KO forced:   Charon‚Üí{KO_NEURAL_FOR_CHARON}, Laomedeia‚Üí{KO_NEURAL_FOR_LAOMEDEIA}")
    print(f"    gaps: gloss={GLOSS_GAP_MS}ms, comma={COMMA_GAP_MS}ms")
    print("üìù Î™®Îìú: word=en-US(Chirp3 HD), gloss=ko-KR(Neural2), ÏÑ±Î≥Ñ ÏàúÌôò(ÎÇ®‚ÜíÏó¨‚ÜíÎÇ®‚Ä¶), ÎçÆÏñ¥Ïì∞Í∏∞\n")

    last_saved: Optional[str] = None
    fails: List[str] = []

    for i, it in enumerate(items):
        lemma = (it.get("lemma") or "").strip()
        categories = it.get("categories")
        ko_gloss_raw = it.get("koGloss") or ""

        if not lemma:
            print(f"[{i+1}/{total}] Í±¥ÎÑàÎúÄ: lemma ÏóÜÏùå")
            continue

        # Í≤ΩÎ°ú
        try:
            paths = build_output_paths(categories, lemma)
        except ValueError as ve:
            if str(ve) == "LEVEL_TAG_MISSING":
                print(f"[{i+1}/{total}] '{lemma}' ‚ùå Î†àÎ≤® ÌÉúÍ∑∏ ÎØ∏Í≤ÄÏ∂ú ‚Üí Ï≤òÎ¶¨ Ï§ëÎã®")
                try:
                    with open("ÎßàÏßÄÎßâ ÏÉùÏÑ± Îã®Ïñ¥.txt", "w", encoding="utf-8") as f:
                        f.write((last_saved or '').strip())
                except Exception:
                    pass
                return
            print(f"[{i+1}/{total}] '{lemma}' Í≤ΩÎ°ú Ïò§Î•ò: {ve}")
            fails.append(f"{lemma}\tPATH_ERROR:{ve}")
            continue

        v = voices_for_index(i)
        print(f"[{i+1}/{total}] '{lemma}' ‚Üí dir='{paths['dir']}', en={v['en']}, ko={v['ko']} (gender={v['gender']})")

        # 1) word.mp3 (en-US)
        word_seg = synthesize_lang_try_voices(tts, lemma, "en-US", [v["en"]])
        if word_seg is None or len(word_seg) == 0:
            print("  ‚ùå word Ìï©ÏÑ± Ïã§Ìå®")
            fails.append(f"{lemma}\tWORD_SYNTH_FAIL:{v['en']}")
            continue
        try:
            word_seg.export(paths["word"], format="mp3")
            print("  ‚úÖ word.mp3 Ï†ÄÏû•(ÎçÆÏñ¥Ïì∞Í∏∞)")
        except Exception as e:
            print(f"  ‚ö†Ô∏è word Ï†ÄÏû• Ïã§Ìå®: {e}")
            fails.append(f"{lemma}\tWORD_SAVE_FAIL:{e}")
            continue

        # 2) gloss.mp3 = word + GLOSS_GAP_MS + koGloss(ko-KR), ÏΩ§ÎßàÎßàÎã§ COMMA_GAP_MS
        ko_gloss = clean_ko_gloss(ko_gloss_raw)
        if not ko_gloss:
            print("  ‚ö†Ô∏è koGloss ÎπÑÏñ¥ÏûàÏùå ‚Üí gloss ÏÉùÎûµ")
            last_saved = lemma
            continue

        # ÏÑ±Î≥ÑÎ≥Ñ ÌïúÍµ≠Ïñ¥ Ìè¥Î∞± ÌõÑÎ≥¥ Íµ¨ÏÑ±
        ko_candidates = [v["ko"]] + (KO_MALE_FALLBACKS if v["gender"] == "male" else KO_FEMALE_FALLBACKS)

        ko_seg = synthesize_with_commas_try_voices(tts, ko_gloss, "ko-KR", COMMA_GAP_MS, ko_candidates)
        if ko_seg is None or len(ko_seg) == 0:
            fails.append(f"{lemma}\tKOGLOSS_SYNTH_FAIL:{'|'.join(ko_candidates)}")
            continue

        gloss_seg = word_seg + AudioSegment.silent(duration=GLOSS_GAP_MS) + ko_seg
        gloss_seg = loudness_normalize(gloss_seg, TARGET_DBFS)

        try:
            gloss_seg.export(paths["gloss"], format="mp3")
            print("  ‚úÖ gloss.mp3 Ï†ÄÏû•(ÎçÆÏñ¥Ïì∞Í∏∞)")
            last_saved = lemma
        except Exception as e:
            print(f"  ‚ö†Ô∏è gloss Ï†ÄÏû• Ïã§Ìå®: {e}")
            fails.append(f"{lemma}\tGLOSS_SAVE_FAIL:{e}")
            continue

    # ÎßàÎ¨¥Î¶¨
    try:
        with open("ÎßàÏßÄÎßâ ÏÉùÏÑ± Îã®Ïñ¥.txt", "w", encoding="utf-8") as f:
            f.write((last_saved or "").strip())
    except Exception:
        pass

    if fails:
        with open("ÏÉùÏÑ± Ïã§Ìå® Î™©Î°ù.txt", "w", encoding="utf-8") as f:
            f.write("\n".join(fails) + "\n")
        print(f"\n‚ö†Ô∏è Ïã§Ìå® {len(fails)}Í±¥ ‚Üí 'ÏÉùÏÑ± Ïã§Ìå® Î™©Î°ù.txt' Í∏∞Î°ù")
    else:
        print("\n‚úÖ Î™®Îì† Ìï≠Î™© Ï≤òÎ¶¨ ÏôÑÎ£å(Ïã§Ìå® ÏóÜÏùå)")

if __name__ == "__main__":
    json_file = sys.argv[1] if len(sys.argv) > 1 else "cefr_vocabs.json"
    process(json_file)
